{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"../Data/Images/Train\"\n",
    "test_path = \"../Data/Images/Test\"\n",
    "valid_path = \"../Data/Images/Valid\"\n",
    "datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<DirEntry 'kick1552.png'>\n",
      "<DirEntry 'kick1528.png'>\n",
      "<DirEntry 'kick1529.png'>\n",
      "<DirEntry 'kick1530.png'>\n",
      "<DirEntry 'kick1531.png'>\n",
      "<DirEntry 'kick1532.png'>\n",
      "<DirEntry 'kick1533.png'>\n",
      "<DirEntry 'kick1534.png'>\n",
      "<DirEntry 'kick1535.png'>\n",
      "<DirEntry 'kick1536.png'>\n",
      "<DirEntry 'kick1537.png'>\n",
      "<DirEntry 'kick1538.png'>\n",
      "<DirEntry 'kick1539.png'>\n",
      "<DirEntry 'kick1540.png'>\n",
      "<DirEntry 'kick1541.png'>\n",
      "<DirEntry 'kick1542.png'>\n",
      "<DirEntry 'kick1543.png'>\n",
      "<DirEntry 'kick1544.png'>\n",
      "<DirEntry 'kick1545.png'>\n",
      "<DirEntry 'kick1546.png'>\n",
      "<DirEntry 'kick1547.png'>\n",
      "<DirEntry 'kick1548.png'>\n",
      "<DirEntry 'kick1549.png'>\n",
      "<DirEntry 'kick1550.png'>\n",
      "<DirEntry 'kick1551.png'>\n",
      "<DirEntry 'snare2026.png'>\n",
      "<DirEntry 'snare2027.png'>\n",
      "<DirEntry 'snare2028.png'>\n",
      "<DirEntry 'snare2029.png'>\n",
      "<DirEntry 'snare2030.png'>\n",
      "<DirEntry 'snare1999.png'>\n",
      "<DirEntry 'snare2000.png'>\n",
      "<DirEntry 'snare2001.png'>\n",
      "<DirEntry 'snare2002.png'>\n",
      "<DirEntry 'snare2003.png'>\n",
      "<DirEntry 'snare2004.png'>\n",
      "<DirEntry 'snare2005.png'>\n",
      "<DirEntry 'snare2006.png'>\n",
      "<DirEntry 'snare2007.png'>\n",
      "<DirEntry 'snare2008.png'>\n",
      "<DirEntry 'snare2009.png'>\n",
      "<DirEntry 'snare2010.png'>\n",
      "<DirEntry 'snare2011.png'>\n",
      "<DirEntry 'snare2012.png'>\n",
      "<DirEntry 'snare2013.png'>\n",
      "<DirEntry 'snare2014.png'>\n",
      "<DirEntry 'snare2015.png'>\n",
      "<DirEntry 'snare2016.png'>\n",
      "<DirEntry 'snare2017.png'>\n",
      "<DirEntry 'snare2018.png'>\n",
      "<DirEntry 'snare2019.png'>\n",
      "<DirEntry 'snare2020.png'>\n",
      "<DirEntry 'snare2021.png'>\n",
      "<DirEntry 'snare2022.png'>\n",
      "<DirEntry 'snare2023.png'>\n",
      "<DirEntry 'snare2024.png'>\n",
      "<DirEntry 'snare2025.png'>\n"
     ]
    }
   ],
   "source": [
    "with os.scandir(test_path) as dir:\n",
    "    for img in dir:\n",
    "        print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageDataGenerator class\n",
    "\n",
    "Keras has this ImageDataGenerator class which allows the users to perform image augmentation on the fly in a very easy way. You can read about that in Keras’s official documentation.\n",
    "\n",
    "Most of the Image datasets that I found online has 2 common formats, the first common format contains all the images within separate folders named after their respective class names, This is by far the most common format I always see online and Keras allows anyone to utilize the flow_from_directory function to easily the images read from the disc and perform powerful on the fly image augmentation with the ImageDataGenerator.\n",
    "\n",
    "The second most common format I found online is, all the images are present inside a single directory and their respective classes are mapped in a CSV or JSON file, but Keras doesn’t support this earlier and one would have to move the images to separate directories with their respective classes names or write a custom generator to handle this case, So I have written a function flow_from_dataframe that recently got accepted to the official keras-preprocessing git repo, that allows you to input a Pandas dataframe which contains the filenames(with or without the extensions) column and a column which has the class names and directly read the images from the directory with their respective class names mapped.\n",
    "\n",
    "[Heres a link to how to use flow_from_dataframe](https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c)\n",
    "\n",
    "[ImageDataGenerator methods](https://medium.com/datadriveninvestor/keras-imagedatagenerator-methods-an-easy-guide-550ecd3c0a92)\n",
    "\n",
    "The ImageDataGenerator class has three methods flow(), flow_from_directory() and flow_from_dataframe() to read the images from a big numpy array and folders containing images.\n",
    "![](https://miro.medium.com/max/1400/1*HpvpA9pBJXKxaPCl5tKnLg.jpeg)\n",
    "\n",
    "As you can see in the above picture, the test folder should also contain a single folder inside which all the test images are present(Think of it as “unlabeled” class , this is there because the flow_from_directory() expects at least one directory under the given directory path).\n",
    "\n",
    "The folder names for the classes are important, name(or rename) them with respective label names so that it would be easy for you later.\n",
    "\n",
    "#### Here are the most used attributes along with the flow_from_directory() method.\n",
    "```python\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=r\"./train/\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "```\n",
    "\n",
    "* __directory__ must be set to the path where your ‘n’ classes of folders are present.\n",
    "*  __target_size__ is the size of your input images, every image will be resized to this size.\n",
    "* __color_mode__: if the image is either black and white or grayscale set “grayscale” or if the image has three color channels, set “rgb”.\n",
    "* __batch_size__: No. of images to be yielded from the generator per batch.\n",
    "* __class_mode__: Set “binary” if you have only two classes to predict, if not set to“categorical”, in case if you’re developing an Autoencoder system, both input and the   output would probably be the same image, for this case set to “input”.\n",
    "* __shuffle__: Set True if you want to shuffle the order of the image that is being yielded, else set False.\n",
    "* __seed__: Random seed for applying random image augmentation and shuffling the order of the image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4207 images belonging to 2 classes.\n",
      "Found 1536 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = datagen.flow_from_directory(train_path,target_size=(224,224),color_mode=\"rgb\",batch_size=32,class_mode='binary',shuffle=True,seed=42)\n",
    "valid_batches = datagen.flow_from_directory(valid_path,target_size=(224,224),color_mode=\"rgb\",batch_size=12,class_mode='binary',shuffle=True,seed=42)\n",
    "test_batches = datagen.flow_from_directory(test_path,target_size=(224,224),color_mode=\"rgb\",batch_size=1,class_mode='binary',shuffle=True,seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs,labels = next(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(imgs,titles=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_61 (Conv2D)           (None, 254, 254, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_68 (Activation)   (None, 254, 254, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling (None, 127, 127, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_62 (Conv2D)           (None, 125, 125, 256)     73984     \n",
      "_________________________________________________________________\n",
      "activation_69 (Activation)   (None, 125, 125, 256)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_44 (MaxPooling (None, 62, 62, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_63 (Conv2D)           (None, 60, 60, 256)       590080    \n",
      "_________________________________________________________________\n",
      "activation_70 (Activation)   (None, 60, 60, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "flatten_15 (Flatten)         (None, 230400)            0         \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 64)                14745664  \n",
      "_________________________________________________________________\n",
      "activation_71 (Activation)   (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_72 (Activation)   (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 15,410,689\n",
      "Trainable params: 15,410,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# set up CNN Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),input_shape=(256,256,3)))\n",
    "#model.add(Conv2D(96,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "#model.add(Conv2D(128,(3,3)))\n",
    "model.add(Conv2D(256,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(256,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# output layer has 2 neurons since were predicting 2 classes\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = [\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 84/351 [======>.......................] - ETA: 12:14 - loss: 7.8492 - accuracy: 0.4881"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-f7a634902cf5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# we have to use model.fit_generator since we preprocessed the training data with a generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_batches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# we have to use model.fit_generator since we preprocessed the training data with a generator\n",
    "model.fit_generator(train_batches,validation_data=valid_batches,epochs=10,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning a VGG16 pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 82s 0us/step\n"
     ]
    }
   ],
   "source": [
    "vgg16 = keras.applications.vgg16.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.engine.training.Model"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning the vgg model into a sequential model\n",
    "model = Sequential()\n",
    "# iterate over all the layers (except for the last one) in the vgg16 model\n",
    "# taking off the output layer so we can later re-add it with the amount of classes we need\n",
    "for layer in vgg16.layers[:-1]:\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this sets all the layers to be non trainable so that the weights will stay the same \n",
    "# which is what we want in the case of fine tuning\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the output dense layer\n",
    "model.add(Dense(1,activation=\"softmax\"))\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 2)                 8194      \n",
      "_________________________________________________________________\n",
      "dense_33 (Dense)             (None, 1)                 3         \n",
      "_________________________________________________________________\n",
      "dense_34 (Dense)             (None, 1)                 2         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1)                 4         \n",
      "_________________________________________________________________\n",
      "dense_35 (Dense)             (None, 1)                 2         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 134,276,946\n",
      "Trainable params: 8,197\n",
      "Non-trainable params: 134,268,749\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=.0001),\n",
    "              loss = 'binary_crossentropy',\n",
    "             metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 58/132 [============>.................] - ETA: 8:39 - loss: 7.3052 - accuracy: 0.5264"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-107-f7a634902cf5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# we have to use model.fit_generator since we preprocessed the training data with a generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_batches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# we have to use model.fit_generator since we preprocessed the training data with a generator\n",
    "model.fit_generator(train_batches,validation_data=valid_batches,epochs=10,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
