{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm, tqdm_notebook; tqdm.pandas()\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from filtr import Filtr\n",
    "import random\n",
    "\n",
    "# Machine Learning\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.layers import (Dense, Bidirectional, CuDNNLSTM, ELU,\n",
    "                          Dropout, LeakyReLU, Conv1D, BatchNormalization)\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep\n",
    "- load each audio file into a list that is named after the category (ex. Kick = [], snare = [])\n",
    "- read each sample from each list and convert it to audio data\n",
    "- convert the audio data into a mel spectrogram and also add its category number as well\n",
    "- add the category list into a training list and shuffle it\n",
    "- seperate the features from the labels and pickle the data for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kick\n",
      "Snare\n"
     ]
    }
   ],
   "source": [
    "# load audio files\n",
    "Data_path = \"D:\\\\Documents\\\\Atom\\\\myrepos\\\\Filtr\\\\Filtr\\\\Audio\"\n",
    "Categories = ['Kick','Snare']\n",
    "os.chdir(\"D:\\\\Documents\\\\Atom\\\\myrepos\\\\Filtr\\\\Filtr\")\n",
    "f = Filtr(Data_path,dest = None)\n",
    "\n",
    "snare = []\n",
    "kick = []\n",
    "\n",
    "for category in Categories:\n",
    "    path = os.path.join(Data_path,category)\n",
    "    files = f.files(path)\n",
    "    os.chdir(path)\n",
    "    print(category)\n",
    "    for file in files:\n",
    "        if ('DK' or 'Kick' or 'kick') in file:\n",
    "            full_path = os.path.join(path,file)\n",
    "            kick.append(full_path)\n",
    "        elif (\"DS\" or 'snare') in file:\n",
    "            full_path = os.path.join(path,file)\n",
    "            snare.append(full_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read each sample as audio data\n",
    "import soundfile as sf\n",
    "import sys\n",
    "\n",
    "def trim(y,samples = 44100):\n",
    "    if 0 < len(y): # workaround: 0 length causes error\n",
    "        y, _ = librosa.effects.trim(y)\n",
    "    return y\n",
    "\n",
    "def audio_data(training_names,type = None,category = None):\n",
    "    audio_info = []\n",
    "    error = 0\n",
    "    \n",
    "    \n",
    "    for name in training_names:\n",
    "        try:\n",
    "            # loading the data\n",
    "            \n",
    "            data, samplerate = sf.read(name)\n",
    "            #print(f\"Data before: {data}\\n\")\n",
    "            \n",
    "            data = data[:, 0]\n",
    "            #print(f\"Data after: {data}\")\n",
    "            \n",
    "            # optional trim silence\n",
    "            data = trim(data)\n",
    "            \n",
    "            audio_info.append(data)\n",
    "            #print(f\"filename: {name}\")\n",
    "            \n",
    "        except:\n",
    "            #print(e)\n",
    "            error += 1\n",
    "            #print(f\"there was an error loading this file: {name}\")\n",
    "            #print(\"Unexpected error:\", sys.exc_info()[0])\n",
    "            #print()\n",
    "            #raise\n",
    "            pass\n",
    "            \n",
    "    print(f\"there was an error loading {error} files\")    \n",
    "    return np.array(audio_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there was an error loading 171 files\n",
      "there was an error loading 382 files\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kick_data = audio_data(kick,category = 'kick')\n",
    "snare_data = audio_data(snare,category = 'snare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2976\n",
      "4584\n"
     ]
    }
   ],
   "source": [
    "print(len(kick_data))\n",
    "print(len(snare_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18109"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert audio data into a Mel spectrogram \n",
    "def mel(audio,sr = 44100,size = 150):\n",
    "    spectrograms = []\n",
    "    error = []\n",
    "    try:\n",
    "        for data in audio[:5]:\n",
    "            mel = librosa.feature.melspectrogram(y = data, sr = sr)\n",
    "            mel = librosa.power_to_db(mel,ref=np.max).astype(np.float32)\n",
    "            #mel.resize((size,size))\n",
    "            spectrograms.append(mel) \n",
    "    except:\n",
    "        error.append(data)\n",
    "        pass\n",
    "    if len(error) > 0:\n",
    "        print(f\"there was {len(error)} errors. this is the data \\n{error}\")\n",
    "    return spectrograms   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kick_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kick_data' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "kmels = mel(kick_data)\n",
    "smels = mel(snare_data)\n",
    "#test =[[1,2,3,4,5],['test']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librosa.display.specshow(smels[0][0],y_axis = 'mel',x_axis = 's',sr=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(img):\n",
    "    '''\n",
    "    Normalizes an array \n",
    "    (subtract mean and divide by standard deviation)\n",
    "    '''\n",
    "    eps = 0.001\n",
    "    if np.std(img) != 0:\n",
    "        img = (img - np.mean(img)) / np.std(img)\n",
    "    else:\n",
    "        img = (img - np.mean(img)) / eps\n",
    "    return img\n",
    "\n",
    "def train_data(audio_data,categories,data_limit = None):\n",
    "    '''\n",
    "    This function takes in audio data as a list and the categories as a list and returns a list of training data anolng with\n",
    "    its labels.\n",
    "    \n",
    "    -------------------\n",
    "    parameters\n",
    "    -------------------\n",
    "        audio_data: the audio data list is an array of each of the categories' audio data.\n",
    "            for example:\n",
    "                L1 = [1,2,3,4] -> category1\n",
    "                L2 = [5,6,7,8] -> category2\n",
    "                train_data(audio_data = [L1,L2])\n",
    "        \n",
    "        categories: a list of categories used to determine class labels. The categories must be passed in as the same order\n",
    "        as the audio data passed in and it also must be the same category as used when .\n",
    "            for example:\n",
    "            train_data([L1,L2],[category1,category2])\n",
    "        \n",
    "        data_limit: The amount of trainig data to add for each category. If a number isn't provided it will use the \n",
    "        minimum between all of the audio data lists.\n",
    "                \n",
    "    \n",
    "    '''\n",
    "    train = []\n",
    "    x = []\n",
    "    for data in audio_data:\n",
    "        x.append(len(data))\n",
    "    \n",
    "    print(x)    \n",
    "    data_limit = min(x) if data_limit is None else data_limit\n",
    "    print(f\"Data limit: {data_limit}\")\n",
    "\n",
    "    #print(audio_data[1][0][1])\n",
    "    for datas in audio_data:\n",
    "        for category in categories:\n",
    "            y = 0\n",
    "            for data in datas:\n",
    "                data = normalize(data)\n",
    "                \n",
    "                class_num = categories.index(category)\n",
    "                train.append([data,class_num])\n",
    "                if y == data_limit:\n",
    "                    break\n",
    "                y += 1\n",
    "            if y == data_limit:\n",
    "                break\n",
    "                    \n",
    "    random.seed(66)                \n",
    "    random.shuffle(train)                \n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5]\n",
      "Data limit: 5\n",
      "Wall time: 7.28 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "training = train_data([kmels,smels],['kick','snare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#librosa.display.specshow(X[1],y_axis = 'mel',x_axis = 's',sr=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.2676501,  1.9019651,  1.009496 , ..., -0.8894738, -1.2905978,\n",
       "         -1.1797109],\n",
       "        [ 2.1392572,  1.8092521,  0.9670504, ..., -1.2245531, -1.4794313,\n",
       "         -1.8999516],\n",
       "        [ 1.9215908,  1.5356799,  0.9195003, ..., -1.6863644, -1.8874991,\n",
       "         -2.0193913],\n",
       "        ...,\n",
       "        [ 1.8183211,  1.5977492,  1.3123639, ..., -2.0250356, -2.0459478,\n",
       "         -2.0471504],\n",
       "        [ 1.9065216,  1.7477198,  1.5279608, ..., -1.9491813, -1.9058753,\n",
       "         -2.018233 ],\n",
       "        [ 1.9437186,  1.8265319,  1.582386 , ..., -1.9550165, -1.9999135,\n",
       "         -2.023254 ]], dtype=float32), 0]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for feat,label in training:\n",
    "    #print(feat)\n",
    "    X.append(np.resize(feat,(128,128)))\n",
    "    y.append(label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "os.chdir(\"D:\\\\Documents\\\\Atom\\\\myrepos\\\\Filtr\\\\Filtr\")\n",
    "with open('X.pickle','wb') as file:\n",
    "    pickle.dump(X,file)\n",
    "    \n",
    "with open('y.pickle','wb') as file:\n",
    "    pickle.dump(y,file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
