{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"E:\\Documents\\My Progects\\Filtr\\Data\\Images\\Train\"\n",
    "test_path = r\"E:\\Documents\\My Progects\\Filtr\\Data\\Images\\Test\"\n",
    "valid_path = r\"E:\\Documents\\My Progects\\Filtr\\Data\\Images\\valid\"\n",
    "datagen = ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "with os.scandir(test_path) as dir:\n",
    "    for img in dir:\n",
    "        print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImageDataGenerator class\n",
    "\n",
    "Keras has this ImageDataGenerator class which allows the users to perform image augmentation on the fly in a very easy way. You can read about that in Keras’s official documentation.\n",
    "\n",
    "Most of the Image datasets that I found online has 2 common formats, the first common format contains all the images within separate folders named after their respective class names, This is by far the most common format I always see online and Keras allows anyone to utilize the flow_from_directory function to easily the images read from the disc and perform powerful on the fly image augmentation with the ImageDataGenerator.\n",
    "\n",
    "The second most common format I found online is, all the images are present inside a single directory and their respective classes are mapped in a CSV or JSON file, but Keras doesn’t support this earlier and one would have to move the images to separate directories with their respective classes names or write a custom generator to handle this case, So I have written a function flow_from_dataframe that recently got accepted to the official keras-preprocessing git repo, that allows you to input a Pandas dataframe which contains the filenames(with or without the extensions) column and a column which has the class names and directly read the images from the directory with their respective class names mapped.\n",
    "\n",
    "[Heres a link to how to use flow_from_dataframe](https://medium.com/@vijayabhaskar96/tutorial-on-keras-flow-from-dataframe-1fd4493d237c)\n",
    "\n",
    "[ImageDataGenerator methods](https://medium.com/datadriveninvestor/keras-imagedatagenerator-methods-an-easy-guide-550ecd3c0a92)\n",
    "\n",
    "The ImageDataGenerator class has three methods flow(), flow_from_directory() and flow_from_dataframe() to read the images from a big numpy array and folders containing images.\n",
    "![](https://miro.medium.com/max/1400/1*HpvpA9pBJXKxaPCl5tKnLg.jpeg)\n",
    "\n",
    "As you can see in the above picture, the test folder should also contain a single folder inside which all the test images are present(Think of it as “unlabeled” class , this is there because the flow_from_directory() expects at least one directory under the given directory path).\n",
    "\n",
    "The folder names for the classes are important, name(or rename) them with respective label names so that it would be easy for you later.\n",
    "\n",
    "#### Here are the most used attributes along with the flow_from_directory() method.\n",
    "```python\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=r\"./train/\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "```\n",
    "\n",
    "* __directory__ must be set to the path where your ‘n’ classes of folders are present.\n",
    "*  __target_size__ is the size of your input images, every image will be resized to this size.\n",
    "* __color_mode__: if the image is either black and white or grayscale set “grayscale” or if the image has three color channels, set “rgb”.\n",
    "* __batch_size__: No. of images to be yielded from the generator per batch.\n",
    "* __class_mode__: Set “binary” if you have only two classes to predict, if not set to“categorical”, in case if you’re developing an Autoencoder system, both input and the   output would probably be the same image, for this case set to “input”.\n",
    "* __shuffle__: Set True if you want to shuffle the order of the image that is being yielded, else set False.\n",
    "* __seed__: Random seed for applying random image augmentation and shuffling the order of the image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4207 images belonging to 2 classes.\n",
      "Found 1536 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "train_batches = datagen.flow_from_directory(train_path,target_size=(224,224),color_mode=\"rgb\",batch_size=32,class_mode='binary',shuffle=True,seed=42)\n",
    "valid_batches = datagen.flow_from_directory(valid_path,target_size=(224,224),color_mode=\"rgb\",batch_size=12,class_mode='binary',shuffle=True,seed=42)\n",
    "test_batches = datagen.flow_from_directory(test_path,target_size=(224,224),color_mode=\"rgb\",batch_size=1,class_mode='binary',shuffle=True,seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plots(ims, figsize=(12,6), rows=1, interp=False, titles=None):\n",
    "    if type(ims[0]) is np.ndarray:\n",
    "        ims = np.array(ims).astype(np.uint8)\n",
    "        if (ims.shape[-1] != 3):\n",
    "            ims = ims.transpose((0,2,3,1))\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
    "    for i in range(len(ims)):\n",
    "        sp = f.add_subplot(rows, cols, i+1)\n",
    "        sp.axis('Off')\n",
    "        if titles is not None:\n",
    "            sp.set_title(titles[i], fontsize=16)\n",
    "        plt.imshow(ims[i], interpolation=None if interp else 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs,labels = next(train_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 32 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plots(imgs,titles=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# set up CNN Model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),input_shape=(256,256,3)))\n",
    "#model.add(Conv2D(96,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "#model.add(Conv2D(128,(3,3)))\n",
    "model.add(Conv2D(256,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(256,(3,3)))\n",
    "model.add(Activation(\"relu\"))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# output layer has 2 neurons since were predicting 2 classes\n",
    "model.add(Dense(1))\n",
    "model.add(Activation(\"softmax\"))\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "             optimizer = 'adam',\n",
    "             metrics = [\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning a VGG16 pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = keras.applications.vgg16.VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning the vgg model into a sequential model\n",
    "model = Sequential()\n",
    "# iterate over all the layers (except for the last one) in the vgg16 model\n",
    "# taking off the output layer so we can later re-add it with the amount of classes we need\n",
    "for layer in vgg16.layers[:-1]:\n",
    "    model.add(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "=================================================================\n",
      "Total params: 134,260,544\n",
      "Trainable params: 134,260,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this sets all the layers to be non trainable so that the weights will stay the same \n",
    "# which is what we want in the case of fine tuning\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the output dense layer\n",
    "model.add(Dense(1,activation=\"softmax\"))\n",
    "model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 4097      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 134,264,645\n",
      "Trainable params: 4,099\n",
      "Non-trainable params: 134,260,546\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=.0001),\n",
    "              loss = 'binary_crossentropy',\n",
    "             metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "132/132 [==============================] - 1914s 14s/step - loss: 7.3553 - accuracy: 0.5237 - val_loss: 0.6794 - val_accuracy: 0.5625\n",
      "Epoch 2/5\n",
      "132/132 [==============================] - 1271s 10s/step - loss: 7.3553 - accuracy: 0.5237 - val_loss: 0.9054 - val_accuracy: 0.4375\n",
      "Epoch 3/5\n",
      "132/132 [==============================] - 1243s 9s/step - loss: 7.3553 - accuracy: 0.5237 - val_loss: 0.9234 - val_accuracy: 0.4375\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-1f2a328f2439>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# we have to use model.fit_generator since we preprocessed the training data with a generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_batches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_batches\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1732\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1733\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m                                             reset_metrics=False)\n\u001b[0m\u001b[0;32m    221\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# we have to use model.fit_generator since we preprocessed the training data with a generator\n",
    "model.fit_generator(train_batches,validation_data=valid_batches,epochs=5,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs, test_labels = next(test_batches)\n",
    "plots(test_imgs,titles=test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
